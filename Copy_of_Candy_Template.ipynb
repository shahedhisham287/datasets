{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6SgGJgCt2i0S"
      },
      "source": [
        "# Project: cleanning - [candy data]\n",
        "### this notebook is for educational purpose . in this notebook we will do some cleanning\n",
        "\n",
        "## Table of Contents\n",
        "<ul>\n",
        "<li><a href=\"#intro\">Introduction</a></li>\n",
        "<li><a href=\"#wrangling\">wrangling</a></li>\n",
        "  \n",
        "</ul>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OA7ee8V_2i0b"
      },
      "source": [
        "<a id='intro'></a>\n",
        "## Introduction\n",
        "\n",
        "### Dataset Description\n",
        "\n",
        "> i will go through candy data 2017 , this data has :\n",
        "- Internal_ID\n",
        "- Q1-Going Out?: Are you actually going trick or treating yourself? \"has values `Yes or No`\"\n",
        "- Q2-Gender: It has four different options, `Femal ,Male ,Other ,I'd rather not say`\n",
        "- Q3-Age: Numerical field\n",
        "- Q4-Country: Text Field, but users have written their own version of the names. Example, for America, there are entries such as USA, us, US, America so we should consider that while cleanning\n",
        "- Q5-State/Province: Text Field, but users have written their own version of the names. Same as the country data.\n",
        "- Q6-Joy Or Despair: All kinds of chocolate bars are the questions with three distinct options to choose from (Joy, Meh, Despair).\n",
        "- Q7-Joy Other: Text Field to write items not included above that give you JOY. Lots of missing values.\n",
        "- Q8-Despair Other: Text Field ti write items not included above that give you DESPAIR. Lots of missing values.\n",
        "- Q9-Other Comments: Text Field. Lots of missing values.\n",
        "- Q10-Dress: Binary field. Missing values present\n",
        "- Unnamed: 113\n",
        "- Q11-Day: Binary Answer Field. Missing values present\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvfaDrWm2i0d"
      },
      "source": [
        "# 1- import packages and load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SsI1SD5t2i0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "outputId": "ff1f35a8-c279-4d47-9e9d-8ff9e4b2b6b4"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-5f4d9b857efa>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"candyhierarchy2017.xlsx\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, decimal, comment, skipfooter, convert_float, mangle_dupe_cols, storage_options)\u001b[0m\n\u001b[1;32m    480\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m         \u001b[0mshould_close\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m         \u001b[0mio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m         raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_buffer, engine, storage_options)\u001b[0m\n\u001b[1;32m   1650\u001b[0m                 \u001b[0mext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xls\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1651\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1652\u001b[0;31m                 ext = inspect_excel_format(\n\u001b[0m\u001b[1;32m   1653\u001b[0m                     \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1654\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36minspect_excel_format\u001b[0;34m(content_or_path, storage_options)\u001b[0m\n\u001b[1;32m   1523\u001b[0m         \u001b[0mcontent_or_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent_or_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1525\u001b[0;31m     with get_handle(\n\u001b[0m\u001b[1;32m   1526\u001b[0m         \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1527\u001b[0m     ) as handle:\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    863\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 865\u001b[0;31m             \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    866\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'candyhierarchy2017.xlsx'"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import fuzzywuzzy\n",
        "from fuzzywuzzy import fuzz\n",
        "from fuzzywuzzy import process\n",
        "df = pd.read_excel(\"candyhierarchy2017.xlsx\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPyfKXEM2i0g"
      },
      "source": [
        "<a id='wrangling'></a>\n",
        "## Data Wrangling\n",
        "\n",
        "\n",
        "\n",
        "### General Properties"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-M7br742i0h"
      },
      "source": [
        "# 2- show some general properties for the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_EQn9-ix2i0i",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "outputId": "4f1bffeb-e6a9-4e75-cae2-2fd7dde5c7dc"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-0a341f18e68f>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ],
      "source": [
        "df.info()\n",
        "df.shape\n",
        "df.dtypes\n",
        "df.columns\n",
        "df.describe()\n",
        "df.duplicated().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mj1Fq-Fk2i0i"
      },
      "source": [
        "# 3- write summary about what you get form the above functions\n",
        "> #### tips : this summary can be about : if there is any missing values , if there a wrong data type , if there a wrong range of values , ...."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PY0Xj3CP2i0j"
      },
      "outputs": [],
      "source": [
        "noticed alot of missing values and the first row consist of all null values that need to be fill, the age column need to be changed to integer , column names arent helpful and need to be changed to easier format to be ease the cleaning process,some columns\n",
        "doesnt seem to be imporant like unnammed and click coordinates"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7wLYsVE2i0k"
      },
      "source": [
        "# cleaning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TcMFeTPo2i0k"
      },
      "source": [
        "### 4- drop all the useless columns and  rows with too much NaN ,\n",
        "> tip : useless columns can be like `Internal ID`and can be also columns with too much NaN\n",
        "- rename columns for easy access"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5xc85dL42i0l"
      },
      "outputs": [],
      "source": [
        "df.drop('Unnamed: 113',axis=1,inplace=True)\n",
        "df.drop('Click Coordinates (x, y)',axis=1,inplace=True)\n",
        "df.drop([0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAPf_aMd2i0l"
      },
      "source": [
        "### 5 - clean `going out` column\n",
        "> tip : you should choose which best value to put in place of these NaNs ( mode, unknown,other ....etc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SLm0XxTE2i0m"
      },
      "outputs": [],
      "source": [
        "df['Q1: GOING OUT?'].unique()\n",
        "modee_Q1=df['Q1: GOING OUT?'].mode()\n",
        "df['Q1: GOING OUT?'].fillna(modee_Q1[0],inplace=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SPbXeXB32i0m"
      },
      "source": [
        "### 6 - clean ` gender` column\n",
        "> tip : you should choose which best value to put in place of these NaNs ( mode, unknown,other ....etc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8PgIzv_G2i0m"
      },
      "outputs": [],
      "source": [
        "df['Q2: GENDER'].unique()\n",
        "df['Q2: GENDER'].fillna(\"I'd rather not say\",inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3OB4AmiU2i0n"
      },
      "source": [
        "### 7 - clean ` age` column\n",
        "> tip : note the type of age column , and NaN values\n",
        " - try to use `to_numeric`\n",
        " - tip : you should choose which best value to put in place of these NaNs ( mean, median, ....etc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jMSyPcVt2i0n"
      },
      "outputs": [],
      "source": [
        "df['Q3: AGE'].unique()\n",
        "df['Q3: AGE']=pd.to_numeric(df['Q3: AGE'], errors ='coerce')\n",
        "meann=df['Q3: AGE'].mean() ##will use it to replace strange values with the average age\n",
        "df['Q3: AGE'].replace(0,meann,inplace=True)\n",
        "df.loc[ df['Q3: AGE'] > 100 , 'Q3: AGE'] = meann\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdcZiNSx2i0o"
      },
      "source": [
        "### 8 - clean ` country` column\n",
        "> tip : note that country column has country names with different writing ways\n",
        "  - use fuzzywuzzy to deal with this problem\n",
        "  - you should choose which best value to put in place of these NaNs ( mode, unknown,other ....etc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JqHvt5LA2i0o"
      },
      "outputs": [],
      "source": [
        "df['Q4: COUNTRY'].unique()\n",
        "countries=pd.DataFrame({\"country\":[\"USA\",\"United states\",\"America\",\"UK\",\"United kingdom\",\"Canada\",\"UAE\",\"Mexico\",\"France\",\"Finland\",\"Netherlands\",\n",
        "                     \"Germany\",\"Costa Rica\",\"Australia\",\"Greece\",\"Ireland\",\"Korea\",\"Japan\",\"South Africa\",\"Iceland\",\"Switzerland\",\"Scotland\",\n",
        "                     \"Denmark\",\"Spain\",\"Indonesia\",\"Netherlands\",\"Atlantis\",\"Singapore\",\"Hong Kong\",\"Taiwan\"]})\n",
        "df['Q4: COUNTRY'].fillna(\"0\",inplace=True)\n",
        "def find_best_match(value, choices):\n",
        "    if pd.isnull(value):\n",
        "        return value\n",
        "    return process.extractOne(str(value), choices)[0]\n",
        "df['Q4: COUNTRY'] = df['Q4: COUNTRY'].apply(lambda x: find_best_match(x, countries['country']))\n",
        "df['Q4: COUNTRY'].replace(\"USA\",\"United states\",inplace=True)\n",
        "df['Q4: COUNTRY'].replace(\"America\",\"United states\",inplace=True)\n",
        "df['Q4: COUNTRY'].replace(\"UK\",\"United kingdom\",inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gNmfcFB2i0p"
      },
      "source": [
        "### 9 - clean ` area` column\n",
        "> tip : area column has the same problem as country columns , but looking at all it's unique values may give us another way to deal with it rather than try to fix it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0AAKa6__2i0p"
      },
      "outputs": [],
      "source": [
        "df.rename(columns = {'Q5: STATE, PROVINCE, COUNTY, ETC':'Q5:Area'}, inplace = True)\n",
        "df[\"Q5:Area\"].unique()\n",
        "##sice many values doesn't have a meaning and can't be determined ,its would be suffiecient  to only use information from country column and drop this one\n",
        "df.drop(\"Q5:Area\",axis=1,inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43BZAOvr2i0p"
      },
      "source": [
        "### 10 - clean ` Q6` columns\n",
        ">- tip : Q6 has all kinds of chocolate bars and questions with three distinct options to choose from (Joy, Meh, Despair).\n",
        "- so all the column that has Q6 is a candy name , so you should go through all these column and you should choose which best value to put in place of these NaNs ( mode, unknown,other ....etc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nD1-HsGM2i0q"
      },
      "outputs": [],
      "source": [
        "for j in df:\n",
        "     if j[1]=='6':\n",
        "        modee=df[j].mode()\n",
        "        df[j].fillna(modee[0],inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJBv4bPN2i0q"
      },
      "source": [
        "### 11 - clean ` dress` column\n",
        ">tip : you should choose which best value to put in place of these NaNs ( mode, unknown,other ....etc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y386_ojC2i0r"
      },
      "outputs": [],
      "source": [
        "df[\"Q10: DRESS\"].isna().sum()\n",
        "df[\"Q10: DRESS\"].unique()\n",
        "modee_dress=df[\"Q10: DRESS\"].mode()\n",
        "df[\"Q10: DRESS\"].fillna(modee_dress[0],inplace=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6fs6Seek2i0r"
      },
      "source": [
        "### 12 - clean ` day` column\n",
        ">tip : you should choose which best value to put in place of these NaNs ( mode, unknown,other ....etc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-GSXv7Jo2i0r"
      },
      "outputs": [],
      "source": [
        "df['Q11: DAY'].unique()\n",
        "modee_day=df['Q11: DAY'].mode()\n",
        "df['Q11: DAY'].fillna(modee_day[0],inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COrRJuN62i0r"
      },
      "source": [
        "### 13 - check\n",
        "> after finish cleaning you should make sure your data is clean and that :\n",
        "- there is no wrong data type\n",
        "- there is no NaN values\n",
        "- all the column are cleaing and ready for the next step `EDA`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UdC7QcCs2i0r"
      },
      "source": [
        "### 14 - write a summary about all the cleaning steps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NehvP9m32i0s"
      },
      "outputs": [],
      "source": [
        "#most of the cleaning process depended on the replacing of nan values and it was done either by getting the mode(frequently used value) and using it or looking through unique values of column and using one.\n",
        "##the age column needed to be changed to another datatype (float) and replacing null values and nonlogical ages with the mean as it is the most conveniant\n",
        "##the country column was cleaned by filling all null values with any value and creating a list with the true value ,giving a function that check the similarities and replace it\n",
        "##since some countries its shortcut can also be used , i replaced the shortcut with fullname\n",
        "##columns that are merged to one question: a loop was used to check the name of each column and perfom the function on it\n",
        "##some columns was dropped as it had no meaning"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}